package streaming

import org.apache.kafka.clients.consumer.ConsumerConfig

import org.apache.spark.SparkConf
//import org.apache.spark.streaming.kafka09.{ConsumerStrategies, KafkaUtils, LocationStrategies}
import org.apache.spark.streaming.kafka09._
import org.apache.spark.streaming.{ Seconds, StreamingContext }

/**
  * Created by Vinayaka Meghraj on 9/28/2017.
  */
object SparkKafkaConsumer {
  def main(args: Array[String]) = {
    if (args.length < 2) {
      System.err.println("Usage: SparkKafkaConsumerDemo <brokers> <topic consume> <topic produce>.")
      System.exit(1)
    }
    val groupId = "testgroup"
    val offsetReset = "earliest"
    val pollTimeout = "1000"
    val Array(broker, topicc, topicp) = args

    val sparkConf = new SparkConf()
      .setAppName(SparkKafkaConsumer.getClass.getName)
      .set("spark.cores.max", "1")

    val ssc = new StreamingContext(sparkConf, Seconds(2))
    //ssc.checkpoint("~/tmp")

    val topicsSet = topicc.split(",").toSet

    val kafkaParams = Map[String, String](
      //ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG -> brokers,
      ConsumerConfig.GROUP_ID_CONFIG -> groupId,
      ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG ->
        "org.apache.kafka.common.serialization.StringDeserializer",
      ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG ->
        "org.apache.kafka.common.serialization.StringDeserializer",
      //ConsumerConfig.AUTO_OFFSET_RESET_CONFIG -> offsetReset,
      //      ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG -> "true",
      //      ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG -> "1000",
    )

    val consumerStrategy = ConsumerStrategies.Subscribe[String, String](topicsSet, kafkaParams)
    val messages = KafkaUtils.createDirectStream[String, String](ssc, LocationStrategies.PreferConsistent, consumerStrategy)
    //messages.count().print()
    messages.foreachRDD{ rdd =>
      val offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges
      print(rdd.count())
      messages.asInstanceOf[CanCommitOffsets].commitAsync(offsetRanges)
    }

    ssc.start()
    ssc.awaitTermination()

    ssc.stop(stopSparkContext = true, stopGracefully = true)
  }
}
#!/bin/bash
# jbenninghoff 2013-Mar-8 vi: set ai et sw=3 tabstop=3:
# jcrutsinger 12-21-2016 - Updated some params, added compression off, added user checking, added ‘time’ to job runs, and removed logging

# Check to make sure script is ran as mapr
if [[ $USER != "mapr" ]]; then
echo "This script must be run as mapr user."
exit 1
fi

### TeraGen (specify size using 100 Byte records)
### Uncomment what size you want to use: 10GB, 50GB, 100GB, 500GB, 1TB

size=$[100*1000*1000]  #10GB for quick runs when tuning
##size=$[500*1000*1000]  #50GB for quick runs when tuning
##size=$[5*1000*1000*1000]  #500GB for quick runs when tuning
##size=$[1*1000*1000*1000]  #100GB for quick runs when tuning
##size=$[10*1000*1000*1000] #1TB for full TeraSort run

chunksize=$[1*256*1024*1024] # default size
chunksize=$[3*256*1024*1024] # Fat map tasks
maps=$[($size*100)/$chunksize] #Map count for TeraGen resulting in no sharded/chunked files
maps=$(echo $maps | awk '{printf "%.0f\n", $1*1.05}') #Bash doesnt do floating point
hadooppath=$(ls -d /opt/mapr/hadoop/hadoop-* -c1 | sort -n | tail -1 | xargs echo) #find latest hadoop installed

#TBD Check for existing teragen data and skip teragen if OK.  Ask user.
if (hadoop fs -stat /benchmarks/tera/input); then
echo "Using existing TeraGen data"
echo "Use: hadoop fs -rm -r /benchmarks/tera/input, to remove and trigger new TeraGen"
sleep 3
else
echo "Benchmarks Volume does not exist, creating it now"
maprcli volume create -name benchmarks -path /benchmarks -replication 1 # use -topology /data... if desired
sleep 3
hadoop fs -rm -r /benchmarks/tera/input #Delete previous data generated by teragen
hadoop fs -chmod 777 /benchmarks
hadoop fs -mkdir /benchmarks/tera
hadoop mfs -setcompression off /benchmarks
hadoop mfs -setcompression off /benchmarks/tera/*
hadoop mfs -setchunksize $chunksize /benchmarks/tera  #Set MFS chunksize to 768MB for fat map tasks
[ $? -ne 0 ] && { echo "setchunksize failed, set chunksize on /benchmarks/tera to $chunksize manually"; exit; }

# Run TeraGen
time hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar teragen \
-Dmapreduce.job.maps=$maps \
-Dmapreduce.map.disk=0 \
-Dmapreduce.map.cpu.vcores=0 \
-Dmapreduce.map.speculative=false \
-Dmapreduce.job.label=odp \
$size /benchmarks/tera/input
sleep 3
fi

hadoop mfs -ls /benchmarks/tera/input | grep ^-rwx | tail

# Define vars for TeraSort run
logname=terasort-$(date -Imin|cut -c-16).log
nodes=$(maprcli node list -columns hostname,cpus,service |grep nodemanager |wc --lines)
((rtasks=nodes*${1:-2})) # Start with 2 reduce tasks per node, reduce tasks per node limited by available RAM
echo nodes=$nodes | tee $logname
echo rtasks=$rtasks | tee -a $logname
hadoop fs -rm -r /benchmarks/tera/output

case $chunksize in
$[3*256*1024*1024] )
echo "Running TeraSort (size=$size) using 'fat' map tasks (fewer map tasks, reduces MxR shuffle)"
sleep 2
time hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar terasort \
-Dmapreduce.map.disk=0 \
-Dmapreduce.map.cpu.vcores=0 \
-Dmapreduce.map.output.compress=false \
-Dmapreduce.map.sort.spill.percent=0.99 \
-Dmapreduce.map.memory.mb=2000 \
-Dmapreduce.map.java.opts="-Xmx1900m -Xms1900m" \
-Dmapreduce.task.io.sort.mb=1500 \
-Dmapreduce.task.io.sort.factor=100 \
-Dmapreduce.reduce.disk=0 \
-Dmapreduce.reduce.cpu.vcores=0 \
-Dmapreduce.reduce.shuffle.parallelcopies=$nodes \
-Dmapreduce.reduce.merge.inmem.threshold=0 \
-Dmapreduce.job.reduces=$rtasks \
-Dmapreduce.job.reduce.slowstart.completedmaps=0.85 \
-Dyarn.app.mapreduce.am.log.level=ERROR \
-Dmapreduce.job.label=odp \
/benchmarks/tera/input /benchmarks/tera/output 2>&1 | tee terasort.tmp
;;
$[1*256*1024*1024] )
echo "Running TeraSort (size=$size) using normal map tasks (more map tasks)"
sleep 2
time hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar terasort \
-Dmapreduce.map.disk=0 \
-Dmapreduce.map.cpu.vcores=0 \
-Dmapreduce.map.output.compress=false \
-Dmapreduce.map.sort.spill.percent=0.99 \
-Dmapreduce.reduce.disk=0 \
-Dmapreduce.reduce.cpu.vcores=0 \
-Dmapreduce.reduce.shuffle.parallelcopies=$nodes \
-Dmapreduce.reduce.merge.inmem.threshold=0 \
-Dmapreduce.task.io.sort.mb=480 \
-Dmapreduce.task.io.sort.factor=100 \
-Dmapreduce.job.reduces=$rtasks \
-Dmapreduce.job.reduce.slowstart.completedmaps=0.55 \
-Dyarn.app.mapreduce.am.log.level=ERROR \
-Dmapreduce.job.label=odp \
/benchmarks/tera/input /benchmarks/tera/output 2>&1 | tee terasort.tmp
;;
*) echo Undefined chunk size!; exit ;;
esac

echo "==================================="
echo "= ODP TeraGenSort Tests Completed ="
echo "==================================="

exit 0;